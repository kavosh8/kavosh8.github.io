---
layout: default
---

[home](./index.html)|[about me](./another-page.html)|[other interests](./other.html)

welcome to my homepage!

I am an AI scientist whose career goal is to understand computational principles underlying intelligence. More specifically, I study agents that interact with a sequential environment to improve their behavior through trial and error. This agent-environment interaction is referred to as the reinforcement learning problem.

I am a senior scientist at Meta's RL team. I have a PhD and an extensive background in the theoretical and empirical foundations of reinforcement learning. I have published more than a dozen papers at top-tier AI conferences such as Neurips, ICML, ICLR, AAAI, and ACL. On the academic side, I am really interested in understanding the optimization problem that arises in the context of learning the value function. On the aplication side, I am quite interested in the developing assistive AI agents that interact with humans and learn from feedback to provide better service. My aspiration is to make AI agents that co-exist with us and help us live our best lives.

The best way to reach me for career-related stuff is by shooting me an email at my first name @alumni.brown.edu. I am genuinely interested in forming meaningful connections with fellow AI scientists, engineers, students, etc, so feel free to reach out even if we never met in person.

## News
*   Moved to Meta's RL team. Also excited to move back to the bay area.
*   Our paper on Fairness in Reinforcement Learning is accepted at RLC, the first instance of  the Reinforcement Learning Conference. Super Excited to meet our wonderful community in Amherst!
*   Our paper on learning the target network in function space got into ICML 2024. I am super excited about this one, so please stay tuned!
* 	Our paper on foundation models for continual learning was accepted at ICLR 2024.
*   Will present two papers at Neurips 2023. (See you again in New Orleans!)
*   Gave a talk at Seattle Mind and Machines meetup on UW's beautiful campus.
*   Gave a talk at Amazon's RL reading group.
*   Moved from Oahu, Hawaii to Seattle, WA.
*   One paper accepted at AISTATS 2022.
*   Coauthered the RL chapter of the D2L book.
*   Two papers accepted at Neurips 2022.
*   Gave a guest lecture at Harvard's ML class.
*   Moved from SF bay area to WFHH (Work From Home in Hawaii)
*	One paper accepted at Neurips 2021.
*   Two papers accepted at AAAI 2021.
*   Moved from Providence, RI to SF bay area.


## Affiliation
*   2025-Now:  Senior Scientist at Meta
*   2020-2025: Scientist at Amazon (Senior from 2024)
*   2015-2020: PhD Student at Brown University <br> (Advisor: Michael Littman)
*   2013-2015: Master's Student at the University of Alberta <br> (Advisor: Rich Sutton)
*   2008-2013: Undergraduate student at the University of Tehran

<a href="https://scholar.google.com/citations?user=-2qyBJEAAAAJ&hl=en&oi=ao">
  <img src="/assets/img/gs.png" alt="Google Scholar Favicon" width="32" height="32">
</a>
<a href="https://www.linkedin.com/in/kavosh-asadi-029a1780/">
  <img src="/assets/img/linkedin.png" alt="LinkedIn Favicon" width="32" height="32">
</a>
<a href="https://twitter.com/AsadiKavosh">
  <img src="/assets/img/x.png" alt="X Favicon" width="32" height="32">
</a>
<a href="https://dblp.org/pid/192/1404.html">
  <img src="/assets/img/dblp.png" alt="DBLP Favicon" width="32" height="32">
</a>
<a href="./assets/pdfs/My_CV.pdf">
  <img src="/assets/img/resume.png" alt="DBLP Favicon" width="32" height="32">
</a>